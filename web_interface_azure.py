#!/usr/bin/env python3
"""
Self-contained web interface for Azure deployment
Includes both Streamlit UI and optional API functionality in one file
"""

import streamlit as st
import requests
import json
import tempfile
import os
from typing import Optional, List
import threading
import time
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Import the necessary components from the app
from app.document_processor import DocumentProcessor
from app.chain import create_rag_chain
from langchain_core.documents import Document
from pydantic import BaseModel
import uvicorn
from fastapi import FastAPI, File, UploadFile, HTTPException, Form
from fastapi.responses import RedirectResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import asyncio

# Initialize the document processor and chain (lazy loading for better startup)
doc_processor = None
rag_chain = None
startup_error = None

def get_doc_processor():
    """Lazy load document processor with error handling"""
    global doc_processor, startup_error
    if doc_processor is None:
        try:
            print("Initializing document processor...")
            doc_processor = DocumentProcessor()
        except Exception as e:
            startup_error = f"Document processor initialization failed: {str(e)}"
            print(f"ERROR: {startup_error}")
            doc_processor = None
            raise Exception(startup_error)
    return doc_processor

def get_rag_chain():
    """Lazy load RAG chain with error handling"""
    global rag_chain, startup_error
    if rag_chain is None:
        try:
            print("Initializing RAG chain...")
            rag_chain = create_rag_chain()
        except Exception as e:
            startup_error = f"RAG chain initialization failed: {str(e)}"
            print(f"ERROR: {startup_error}")
            rag_chain = None
            raise Exception(startup_error)
    return rag_chain

def check_startup_status():
    """Check if all components are properly initialized"""
    try:
        processor = get_doc_processor()
        chain = get_rag_chain()
        return True, "All components initialized successfully"
    except Exception as e:
        return False, str(e)

# Create FastAPI app for the backend (optional)
api_app = FastAPI(title="Document RAG API", description="Upload documents and ask questions about them")

# Add CORS middleware
api_app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models for request/response
class TextUploadRequest(BaseModel):
    text: str
    metadata: Optional[dict] = None

class DocumentResponse(BaseModel):
    success: bool
    message: str
    document_id: Optional[str] = None
    chunks_processed: Optional[int] = None

class SearchResponse(BaseModel):
    success: bool
    results: List[dict]
    count: int

# API Endpoints
@api_app.get("/")
async def redirect_root_to_docs():
    """Redirect root to API documentation"""
    return RedirectResponse("/docs")

@api_app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "service": "Document RAG API"}

@api_app.post("/upload/text", response_model=DocumentResponse)
async def upload_text(request: TextUploadRequest):
    """Upload raw text content"""
    try:
        # Get document processor (lazy loaded)
        processor = get_doc_processor()
        
        # Process the text
        documents = processor.process_text(request.text, request.metadata or {})
        
        # Add to vector store
        success = processor.add_documents_to_vectorstore(documents)
        
        if success:
            doc_id = documents[0].metadata.get("doc_id") if documents else None
            return DocumentResponse(
                success=True,
                message="Text uploaded and processed successfully",
                document_id=doc_id,
                chunks_processed=len(documents)
            )
        else:
            raise HTTPException(status_code=500, detail="Failed to add documents to vector store")
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing text: {str(e)}")

@api_app.post("/upload/file", response_model=DocumentResponse)
async def upload_file(file: UploadFile = File(...)):
    """Upload a file (PDF, TXT, JSON, XLSX, or CSV)"""
    try:
        # Check file type
        if not file.filename:
            raise HTTPException(status_code=400, detail="No file provided")
        
        file_extension = os.path.splitext(file.filename)[1].lower()
        if file_extension not in ['.txt', '.pdf', '.json', '.xlsx', '.csv', '.jpg', '.jpeg', '.png']:
            raise HTTPException(status_code=400, detail="Unsupported file type. Only .txt, .pdf, .json, .xlsx, .csv, .jpg, .jpeg, and .png files are supported")
        
        # Save file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:
            temp_file.write(file.file.read())
            temp_file_path = temp_file.name
        
        try:
            # Get document processor (lazy loaded)
            processor = get_doc_processor()
            
            # Process the file
            documents = processor.process_file(temp_file_path, {"original_filename": file.filename})
            
            # Add to vector store
            success = processor.add_documents_to_vectorstore(documents)
            
            if success:
                doc_id = documents[0].metadata.get("doc_id") if documents else None
                return DocumentResponse(
                    success=True,
                    message=f"File '{file.filename}' uploaded and processed successfully",
                    document_id=doc_id,
                    chunks_processed=len(documents)
                )
            else:
                raise HTTPException(status_code=500, detail="Failed to add documents to vector store")
        
        finally:
            # Clean up temporary file
            os.unlink(temp_file_path)
    
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing file: {str(e)}")

@api_app.post("/rag/invoke")
async def rag_invoke(request: dict):
    """Invoke the RAG chain"""
    try:
        input_text = request.get("input", "")
        if not input_text:
            raise HTTPException(status_code=400, detail="Input is required")
        
        # Get RAG chain (lazy loaded)
        chain = get_rag_chain()
        
        # Invoke the chain
        result = chain.invoke(input_text)
        
        return {"output": result}
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error invoking RAG chain: {str(e)}")

@api_app.get("/documents/stats")
async def get_document_stats():
    """Get statistics about stored documents"""
    try:
        return {
            "total_documents": "Unknown (implement Pinecone stats retrieval)",
            "vector_store_status": "active",
            "index_name": os.environ.get("PINECONE_INDEX_NAME", "unknown")
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error getting stats: {str(e)}")

# Function to run the API server in a separate thread
def run_api_server():
    """Run the API server in a separate thread"""
    try:
        uvicorn.run(api_app, host="127.0.0.1", port=8001, log_level="error")
    except OSError as e:
        if "Address already in use" in str(e):
            print(f"Port 8001 is already in use. Trying port 8002...")
            try:
                uvicorn.run(api_app, host="127.0.0.1", port=8002, log_level="error")
            except OSError as e2:
                print(f"Port 8002 is also in use. API server will not be available.")
                print("Streamlit interface will continue to work normally.")
        else:
            raise e

# Streamlit Interface
def main():
    st.set_page_config(
        page_title="Document Q&A System",
        page_icon="üìÑ",
        layout="wide"
    )
    
    # Check startup status
    startup_ok, status_msg = check_startup_status()
    if not startup_ok:
        st.error(f"‚ùå Startup Error: {status_msg}")
        st.error("Please check your environment variables and dependencies.")
        st.markdown("""
        ### Troubleshooting Steps:
        1. **Environment Variables**: Ensure PINECONE_API_KEY, AZ_OPENAI_ENDPOINT, AZ_OPENAI_API_KEY are set
        2. **Dependencies**: Check that all required packages are installed
        3. **Azure Portal**: Verify Application Settings in your Web App Configuration
        4. **GitHub Actions**: Check deployment logs for installation errors
        
        ### Required Environment Variables:
        - `PINECONE_API_KEY`: Your Pinecone API key
        - `AZ_OPENAI_ENDPOINT`: Your Azure OpenAI endpoint
        - `AZ_OPENAI_API_KEY`: Your Azure OpenAI API key
        """)
        return
    
    st.title("üìÑ Document Q&A System")
    st.markdown("Upload documents and ask questions about them!")
    st.success("‚úÖ All systems initialized successfully!")
    
    # Initialize session state
    if 'uploaded_files' not in st.session_state:
        st.session_state.uploaded_files = []
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    # Sidebar for document upload
    with st.sidebar:
        st.header("üìÅ Document Upload")
        
        # Text upload option
        st.subheader("Upload Text")
        text_content = st.text_area(
            "Or paste text content here:",
            height=150,
            placeholder="Paste your document text here..."
        )
        
        if st.button("Upload Text", key="upload_text_btn"):
            if text_content.strip():
                upload_text_direct(text_content)
            else:
                st.warning("Please enter some text content.")
        
        st.markdown("---")
        
        # File upload option
        st.subheader("Upload Files")
        uploaded_files = st.file_uploader(
            "Choose PDF, TXT, JSON, XLSX, CSV, JPG, or PNG files:",
            type=['pdf', 'txt', 'json', 'xlsx', 'csv', 'jpg', 'jpeg', 'png'],
            accept_multiple_files=True,
            key="file_uploader"
        )
        
        if st.button("Upload Files", key="upload_files_btn"):
            if uploaded_files:
                upload_files_direct(uploaded_files)
            else:
                st.warning("Please select files to upload.")
        
        st.markdown("---")
        
        # Document management
        st.subheader("üìä Document Stats")
        if st.button("View Statistics", key="stats_btn"):
            show_statistics_direct()
        
        st.markdown("---")
        
        # Clear chat
        if st.button("Clear Chat", key="clear_chat_btn"):
            st.session_state.chat_history = []
            st.success("Chat history cleared!")
    
    # Main content area for Q&A
    st.header("üí¨ Ask Questions")
    
    # Display chat history
    chat_container = st.container()
    with chat_container:
        for i, (question, answer) in enumerate(st.session_state.chat_history):
            with st.chat_message("user"):
                st.write(question)
            with st.chat_message("assistant"):
                st.write(answer)
    
    # Input for new question
    question = st.chat_input("Ask a question about your uploaded documents...")
    
    if question:
        ask_question_direct(question)

def upload_text_direct(text_content: str):
    """Upload text content directly"""
    try:
        with st.spinner("Processing text..."):
            # Get document processor (lazy loaded)
            processor = get_doc_processor()
            
            # Process the text directly
            documents = processor.process_text(text_content, {"source": "web_interface", "type": "text"})
            
            # Add to vector store
            success = processor.add_documents_to_vectorstore(documents)
            
            if success:
                doc_id = documents[0].metadata.get("doc_id") if documents else None
                st.success(f"‚úÖ Text uploaded successfully!")
                st.info(f"Document ID: {doc_id}")
                st.info(f"Chunks processed: {len(documents)}")
            else:
                st.error("‚ùå Failed to upload text")
    
    except Exception as e:
        st.error(f"‚ùå Error uploading text: {str(e)}")

def upload_files_direct(uploaded_files):
    """Upload files directly"""
    for uploaded_file in uploaded_files:
        try:
            # Check file size for images (limit to 10MB to avoid network issues)
            if uploaded_file.name.lower().endswith(('.jpg', '.jpeg', '.png')):
                file_size = len(uploaded_file.getbuffer())
                if file_size > 10 * 1024 * 1024:  # 10MB limit
                    st.warning(f"‚ö†Ô∏è Large image detected ({file_size / (1024*1024):.1f}MB). For better performance, consider resizing images under 10MB.")
                    # Still process but with warning
            
            with st.spinner(f"Processing {uploaded_file.name}..."):
                # Save uploaded file temporarily
                with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{uploaded_file.name}") as tmp_file:
                    tmp_file.write(uploaded_file.getbuffer())
                    tmp_file_path = tmp_file.name
                
                # Get document processor (lazy loaded)
                processor = get_doc_processor()
                
                # Process the file directly
                documents = processor.process_file(tmp_file_path, {"original_filename": uploaded_file.name})
                
                # Add to vector store
                success = processor.add_documents_to_vectorstore(documents)
                
                if success:
                    doc_id = documents[0].metadata.get("doc_id") if documents else None
                    st.success(f"‚úÖ File '{uploaded_file.name}' uploaded successfully!")
                    st.info(f"Document ID: {doc_id}")
                    st.info(f"Chunks processed: {len(documents)}")
                    
                    # Show additional info for image files
                    if uploaded_file.name.lower().endswith(('.jpg', '.jpeg', '.png')):
                        st.success("üñºÔ∏è Image processed with OCR text extraction!")
                        st.info("üìù Extracted text from images is now searchable in your document database.")
                        st.info("üí° For best OCR results, use high-resolution images with clear, readable text.")
                else:
                    st.error(f"‚ùå Failed to upload '{uploaded_file.name}'")
            
            # Clean up temporary file
            os.unlink(tmp_file_path)
        
        except Exception as e:
            st.error(f"‚ùå Error uploading '{uploaded_file.name}': {str(e)}")
            # Provide helpful error message for network issues
            if "network" in str(e).lower() or "connection" in str(e).lower():
                st.error("üîå Network error detected. This might be due to large file sizes or connectivity issues.")
                st.info("üí° Try uploading smaller files or check your internet connection.")

def ask_question_direct(question: str):
    """Ask a question using the RAG system directly"""
    try:
        with st.spinner("Thinking..."):
            # Get RAG chain (lazy loaded)
            chain = get_rag_chain()
            
            # Invoke the chain directly
            result = chain.invoke(question)
            
            # Add to chat history
            st.session_state.chat_history.append((question, result))
            
            # Rerun to display the new message
            st.rerun()
    
    except Exception as e:
        st.error(f"‚ùå Error asking question: {str(e)}")

def show_statistics_direct():
    """Display document statistics directly"""
    try:
        with st.spinner("Fetching statistics..."):
            stats = {
                "total_documents": "Unknown (implement Pinecone stats retrieval)",
                "vector_store_status": "active",
                "index_name": os.environ.get("PINECONE_INDEX_NAME", "unknown")
            }
            st.json(stats)
    
    except Exception as e:
        st.error(f"‚ùå Error fetching statistics: {str(e)}")

if __name__ == "__main__":
    # Check if we should start the API server
    # For local testing, we can skip the API server since Streamlit works directly
    start_api = os.environ.get("START_API_SERVER", "false").lower() == "true"
    
    if start_api:
        print("Starting API server in background...")
        # Start the API server in a background thread
        api_thread = threading.Thread(target=run_api_server, daemon=True)
        api_thread.start()
        # Give the API server a moment to start
        time.sleep(2)
    else:
        print("API server disabled. Streamlit interface will work directly.")
    
    # Run the Streamlit interface
    main()
